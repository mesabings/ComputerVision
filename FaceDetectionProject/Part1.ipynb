{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eA_E12gLNqa7"
   },
   "source": [
    "# Group 8 Final Project\n",
    "## Part 1: YOLO based detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT\n",
    "- The weights file needs to be downloaded from [here](https://pjreddie.com/media/files/yolov3.weights) and the config file from [here](https://github.com/x4nth055/pythoncode-tutorials/tree/master/machine-learning/object-detection/cfg).\n",
    "- To generate the YOLO results, set \"write_results\" to True in the write_people_boxes function\n",
    "- The frames should be in the directory './frames/frames/'\n",
    "\n",
    "### Files that get generated from here\n",
    "- './people_rectangles.csv'\n",
    "- './yolov3_results.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "b6FCGpIVNuCJ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oeDqHFKtNwZd",
    "outputId": "307cea9d-7e05-48c2-8c54-68d1e4a4b12b"
   },
   "outputs": [],
   "source": [
    "path = './'\n",
    "frames_path = './frames/frames/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEZ-q-6IPM7K"
   },
   "source": [
    "## 1 Existing Person Detection Technique: YOLOv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ieY2vsRmPVfd"
   },
   "outputs": [],
   "source": [
    "# thresholds for detection\n",
    "confidence_thresh = 0.7\n",
    "score_thresh = 0.5\n",
    "iou_thresh = 0.5\n",
    "print_thresh = 11\n",
    "\n",
    "# the yolov3 neural network configuration\n",
    "config_path = path + 'yolov3.cfg'\n",
    "# the yolov3 net weights file\n",
    "weights_path = path + 'yolov3.weights'\n",
    "\n",
    "# load the yolov3 network\n",
    "net = cv2.dnn.readNetFromDarknet(config_path, weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "S0JDeib2g_qP",
    "outputId": "73dc4787-98c5-40f3-8ef8-8cea3958c3c4"
   },
   "outputs": [],
   "source": [
    "def write_people_boxes(frames_path, display=False, write_results=False):\n",
    "    preds = []\n",
    "    people = []\n",
    "    # Iterate over frame images\n",
    "    for i in range(1,2000):\n",
    "        # Get filepath\n",
    "        filepath = frames_path + 'seq_' + '0'*(6-len(str(i))) + str(i) + '.jpg'\n",
    "\n",
    "        # Read image\n",
    "        image = cv2.cvtColor(cv2.imread(filepath), cv2.COLOR_BGR2RGB)\n",
    "        # Read image shape\n",
    "        h, w = image.shape[:2]\n",
    "        # Create 4D blobs with pixel intensity between 0 and 1\n",
    "        blob = cv2.dnn.blobFromImage(image, 1/255.0, (w, h))\n",
    "\n",
    "        # Sets the blob as the input of the network\n",
    "        net.setInput(blob)\n",
    "\n",
    "        # Get all the layer names\n",
    "        ln = net.getLayerNames()\n",
    "        ln = [ln[j[0] - 1] for j in net.getUnconnectedOutLayers()]\n",
    "\n",
    "        # Feed forward (inference) and get the network output\n",
    "        layer_outputs = net.forward(ln)\n",
    "\n",
    "        # Parameters for drawing and storing boxes\n",
    "        font_scale = 1\n",
    "        thickness = 1\n",
    "        boxes, confidences = [], []\n",
    "\n",
    "        # Iterate over detected objects\n",
    "        for output in layer_outputs:\n",
    "            for detection in output:\n",
    "\n",
    "                # Look at top 5 detected objects\n",
    "                scores = detection[5:]\n",
    "                # Get class with max score\n",
    "                confidence = np.max(scores)\n",
    "                class_id = np.argmax(scores)\n",
    "\n",
    "                # Filter out weak detections\n",
    "                if confidence > confidence_thresh and class_id == 0:\n",
    "                    # Compute detection box location\n",
    "                    box = detection[:4] * np.array([w, h, w, h])\n",
    "                    (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                    x = int(centerX - (width / 2))\n",
    "                    y = int(centerY - (height / 2))\n",
    "                    boxes.append([x, y, int(width), int(height)])\n",
    "                    confidences.append(float(confidence))\n",
    "\n",
    "        # perform the non maximum suppression to remove duplicate detections\n",
    "        idxs = cv2.dnn.NMSBoxes(boxes, confidences, score_thresh, iou_thresh)\n",
    "\n",
    "        # Display first print_thresh images with corrected boxes (default: false)\n",
    "        if display:\n",
    "            if (i < print_thresh):\n",
    "\n",
    "                final_img = image.copy()\n",
    "\n",
    "                # Ensure at least one detection exists\n",
    "                if len(idxs) > 0:\n",
    "                    # Iterate over corrected detected persons\n",
    "                    for idx in idxs.flatten():\n",
    "                        # Draw detection box\n",
    "                        x, y = boxes[idx][0], boxes[idx][1]\n",
    "                        w, h = boxes[idx][2], boxes[idx][3]\n",
    "                        cv2.rectangle(final_img, (x, y), (x + w, y + h), color=(255,0,0), thickness=thickness)\n",
    "\n",
    "                # Output resulting image\n",
    "                plt.subplot(122)\n",
    "                plt.imshow(final_img)\n",
    "                plt.title('Frame ' + str(i) + \" detection after duplicate removal\"), plt.xticks([]), plt.yticks([])\n",
    "                plt.show()\n",
    "\n",
    "        if len(idxs) > 0:\n",
    "            # Iterate over corrected detected persons\n",
    "            for idx in idxs.flatten():\n",
    "                # Draw detection box\n",
    "                x, y = boxes[idx][0], boxes[idx][1]\n",
    "                w, h = boxes[idx][2], boxes[idx][3]\n",
    "                people.append([i,x,y,w,h])\n",
    "\n",
    "        # Store id and number of detected persons\n",
    "        preds.append([i, len(idxs)])\n",
    "\n",
    "        if (i % 100 == 0): print(str(i)+'th frame')\n",
    "\n",
    "    # Write people boxes in csv file\n",
    "    with open('people_rectangles.csv', 'w') as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        writer.writerow(['image_id', 'x', 'y', 'w', 'h'])\n",
    "        writer.writerows(people)        \n",
    "\n",
    "\n",
    "    # Write results in csv file (default: false)\n",
    "    if write_results:\n",
    "        with open('yolov3_results.csv', 'w') as fp:\n",
    "            writer = csv.writer(fp)\n",
    "            writer.writerow(['id', 'count'])\n",
    "            writer.writerows(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100th frame\n",
      "200th frame\n",
      "300th frame\n",
      "400th frame\n",
      "500th frame\n",
      "600th frame\n",
      "700th frame\n",
      "800th frame\n",
      "900th frame\n",
      "1000th frame\n",
      "1100th frame\n",
      "1200th frame\n",
      "1300th frame\n",
      "1400th frame\n",
      "1500th frame\n",
      "1600th frame\n",
      "1700th frame\n",
      "1800th frame\n",
      "1900th frame\n"
     ]
    }
   ],
   "source": [
    "write_people_boxes(frames_path, display=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
